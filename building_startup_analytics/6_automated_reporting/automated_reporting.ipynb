{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547f960c",
   "metadata": {},
   "source": [
    "# Automated Daily Reports to Telegram Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8df9a9",
   "metadata": {},
   "source": [
    "**Author:**  \n",
    "\n",
    "Pavel Grigoryev\n",
    "\n",
    "**Project Description:**\n",
    "\n",
    "- As our application grows, stakeholders need consistent, automated insights into product performance. \n",
    "- Currently, manual reporting processes are time-consuming and lack standardization.\n",
    "- This project replaces manual reporting with an automated pipeline that generates  insights and sends them straight to team chat, ensuring consistent access to key metrics.\n",
    "\n",
    "**Project Goal:**\n",
    "\n",
    "- To build a complete automated pipeline that generates daily product reports and delivers them to a Telegram chat, providing stakeholders with regular business insights without manual intervention.\n",
    "   \n",
    "**Data Sources:**\n",
    "\n",
    "- `feed_actions` - News feed activity\n",
    "- `message_actions` - Messaging activity \n",
    "\n",
    "**Main Conclusion**\n",
    "\n",
    "- **Data Pipeline Development:** \n",
    "  - Built SQL queries to extract and calculate key product metrics from ClickHouse database\n",
    "- **Automation Framework:** \n",
    "  - Created Airflow DAG for scheduled daily execution with comprehensive error handling\n",
    "- **Chat Delivery System:** \n",
    "  - Integrated Telegram API for automated report distribution directly to team chat\n",
    "- **Business Reporting:** \n",
    "  - Designed comprehensive visualizations covering both application-wide and feature-specific metrics\n",
    "- **Stakeholder Focus:** \n",
    "  - Developed business-ready reports that answer key product performance questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059402b",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d0fda9",
   "metadata": {},
   "source": [
    "In the product database on ClickHouse, the data is stored in the following tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf7cf69",
   "metadata": {},
   "source": [
    "Table feed_actions\n",
    "\n",
    "Field | Description\n",
    "-|-\n",
    "user_id | User ID\n",
    "post_id | Post ID\n",
    "action | Action: view or like\n",
    "time | Timestamp\n",
    "gender | User's gender\n",
    "age | User's age (1 = Male)\n",
    "os | User's OS\n",
    "source | Traffic source\n",
    "country | User's country\n",
    "city | User's city\n",
    "exp_group | A/B test group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cfebb1",
   "metadata": {},
   "source": [
    "Table message_actions\n",
    "\n",
    "Field | Description\n",
    "-|-\n",
    "user_id | Sender's ID\n",
    "receiver_id | Receiver's ID\n",
    "time | Send timestamp\n",
    "gender | Sender's gender\n",
    "age | Sender's age (1 = Male)\n",
    "os | Sender's OS\n",
    "source | Sender's traffic source\n",
    "country | Sender's country\n",
    "city | Sender's city\n",
    "exp_group | Sender's A/B test group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a92634",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# SQL Queries Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd748675",
   "metadata": {},
   "source": [
    "SQL queries for extracting and calculating daily product metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd71c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app_daily_report_queries.py\n",
    "\n",
    "\"\"\"\n",
    "SQL queries for application report\n",
    "\"\"\"\n",
    "\n",
    "QUERY_DAU = \"\"\"\n",
    "    WITH union_data as (\n",
    "        SELECT \n",
    "            toDate(time) as date\n",
    "            , user_id \n",
    "            , max(service = 'feed') as has_feed\n",
    "            , max(service = 'messenger') as has_messenger\n",
    "        FROM (\n",
    "            SELECT\n",
    "                time\n",
    "                , user_id\n",
    "                , 'feed' as service\n",
    "            FROM \n",
    "                feed_actions\n",
    "            UNION ALL\n",
    "            SELECT\n",
    "                time\n",
    "                , user_id\n",
    "                , 'messenger' as service\n",
    "            FROM \n",
    "                message_actions \n",
    "        )\n",
    "        WHERE \n",
    "            toDate(time) BETWEEN yesterday() - 13 AND yesterday()  \n",
    "        GROUP BY \n",
    "            date\n",
    "            , user_id \n",
    "    )\n",
    "    SELECT \n",
    "        date\n",
    "        , uniq(user_id) as total_dau\n",
    "        , uniqIf(user_id, has_feed = 1 and has_messenger = 0) as feed_only_dau\n",
    "        , uniqIf(user_id, has_feed = 0 and has_messenger = 1) as messenger_only_dau\n",
    "        , uniqIf(user_id, has_feed = 1 and has_messenger = 1) as both_services_dau\n",
    "        , if(date >= yesterday() - 6, 'current', 'previous') as week_status\n",
    "    FROM \n",
    "        union_data\n",
    "    GROUP BY \n",
    "        date\n",
    "    ORDER BY \n",
    "        date    \n",
    "\"\"\"        \n",
    "\n",
    "QUERY_NEW_USERS = \"\"\"\n",
    "    WITH first_actions AS (\n",
    "        SELECT \n",
    "            user_id\n",
    "            , toDate(min(time)) as first_date\n",
    "            , toDate(minIf(time, service = 'feed')) as first_feed_date\n",
    "            , toDate(minIf(time, service = 'messenger')) as first_messenger_date\n",
    "        FROM (\n",
    "            SELECT time, user_id, 'feed' as service\n",
    "            FROM feed_actions\n",
    "            UNION ALL\n",
    "            SELECT time, user_id, 'messenger' as service  \n",
    "            FROM message_actions\n",
    "        )\n",
    "        GROUP BY user_id\n",
    "    )\n",
    "    , first_all as (\n",
    "        SELECT \n",
    "        first_date as date\n",
    "        , uniq(user_id) as all_new_users\n",
    "        FROM \n",
    "        first_actions\n",
    "        WHERE \n",
    "        date BETWEEN yesterday() - 13 AND yesterday()\n",
    "        GROUP BY \n",
    "        date\n",
    "    )\n",
    "    , first_feed as (\n",
    "        SELECT \n",
    "        first_feed_date as date\n",
    "        , uniq(user_id) as feed_new_users\n",
    "        FROM \n",
    "        first_actions\n",
    "        WHERE \n",
    "        date BETWEEN yesterday() - 13 AND yesterday()      \n",
    "        GROUP BY \n",
    "        date\n",
    "    )\n",
    "    , first_messenger as (\n",
    "        SELECT \n",
    "        first_messenger_date as date\n",
    "        , uniq(user_id) as messenger_new_users\n",
    "        FROM \n",
    "        first_actions\n",
    "        WHERE \n",
    "        date BETWEEN yesterday() - 13 AND yesterday()      \n",
    "        GROUP BY \n",
    "        date\n",
    "    )\n",
    "    , both_activity as (\n",
    "        SELECT \n",
    "        toDate(time) as date\n",
    "        , user_id\n",
    "        FROM (\n",
    "            SELECT time, user_id, 'feed' as service\n",
    "            FROM feed_actions\n",
    "            UNION ALL\n",
    "            SELECT time, user_id, 'messenger' as service  \n",
    "            FROM message_actions\n",
    "        )\n",
    "        GROUP BY \n",
    "        date\n",
    "        , user_id\n",
    "        HAVING \n",
    "        uniq(service) = 2\n",
    "    )\n",
    "    , first_both as (\n",
    "        SELECT \n",
    "        date\n",
    "        , uniq(user_id) as both_first_users\n",
    "        FROM \n",
    "        both_activity\n",
    "        WHERE \n",
    "        date BETWEEN yesterday() - 13 AND yesterday()      \n",
    "        GROUP BY \n",
    "        date\n",
    "    )\n",
    "    SELECT \n",
    "        a.date as date\n",
    "        , if(date >= yesterday() - 6, 'current', 'previous') as week_status\n",
    "        , ifNull(a.all_new_users, 0) as all_new_users\n",
    "        , ifNull(f.feed_new_users, 0) as feed_new_users\n",
    "        , ifNull(m.messenger_new_users, 0) as messenger_new_users\n",
    "        , ifNull(b.both_first_users, 0) as both_first_users\n",
    "    FROM \n",
    "        first_all a\n",
    "    LEFT JOIN first_feed f ON a.date = f.date\n",
    "    LEFT JOIN first_messenger m ON a.date = m.date\n",
    "    LEFT JOIN first_both b ON a.date = b.date\n",
    "\"\"\"\n",
    "\n",
    "QUERY_ACTIVITY = \"\"\"\n",
    "    WITH feed_stats as (\n",
    "        SELECT \n",
    "            toDate(time) as date\n",
    "            , countIf(action = 'view') as views\n",
    "            , countIf(action = 'like') as likes\n",
    "            , ifNull(likes / nullIf(views, 0), 0) as ctr\n",
    "        FROM \n",
    "            feed_actions\n",
    "        WHERE \n",
    "            date BETWEEN yesterday() - 13 AND yesterday()\n",
    "        GROUP BY \n",
    "            date\n",
    "    )\n",
    "    , messenger_stats as (\n",
    "        SELECT \n",
    "            toDate(time) as date\n",
    "            , count() as messages\n",
    "        FROM \n",
    "            message_actions \n",
    "        WHERE \n",
    "            date BETWEEN yesterday() - 13 AND yesterday()\n",
    "        GROUP BY \n",
    "            date\n",
    "    )    \n",
    "    SELECT \n",
    "        if(f.date != toDate(0), f.date, m.date) as date\n",
    "        , if(date >= yesterday() - 6, 'current', 'previous') as week_status\n",
    "        , ifNull(f.views, 0) as views\n",
    "        , ifNull(f.likes, 0) as likes\n",
    "        , ifNull(f.ctr, 0) as ctr\n",
    "        , ifNull(m.messages, 0) as messages\n",
    "    FROM \n",
    "        feed_stats f\n",
    "        FULL JOIN messenger_stats m ON f.date = m.date\n",
    "    ORDER BY \n",
    "        date\n",
    "\"\"\"    \n",
    "\n",
    "QUERY_RETENTION = \"\"\"\n",
    "    WITH cohorts as (\n",
    "        SELECT \n",
    "            user_id\n",
    "            , toDate(min(time)) as cohort\n",
    "        FROM (\n",
    "            SELECT\n",
    "                time\n",
    "                , user_id\n",
    "            FROM \n",
    "                feed_actions\n",
    "            UNION ALL \n",
    "            SELECT\n",
    "                time\n",
    "                , user_id\n",
    "            FROM \n",
    "                message_actions \n",
    "        )\n",
    "        GROUP BY \n",
    "            user_id \n",
    "        HAVING  \n",
    "            cohort BETWEEN yesterday() - 14 AND yesterday() - 7\n",
    "    )\n",
    "    , activity as (\n",
    "        SELECT \n",
    "            toDate(time) as date\n",
    "            , user_id\n",
    "        FROM (\n",
    "            SELECT\n",
    "                time\n",
    "                , user_id\n",
    "            FROM \n",
    "                feed_actions\n",
    "            UNION ALL  \n",
    "            SELECT\n",
    "                time\n",
    "                , user_id\n",
    "            FROM \n",
    "                message_actions \n",
    "            )\n",
    "        WHERE   \n",
    "            date BETWEEN yesterday() - 14 AND yesterday()\n",
    "        GROUP BY \n",
    "            date\n",
    "            , user_id\n",
    "    )\n",
    "    SELECT \n",
    "        c.cohort\n",
    "        , a.date - c.cohort as lifetime\n",
    "        , uniq(user_id) as users\n",
    "    FROM \n",
    "        cohorts c\n",
    "        JOIN activity a ON c.user_id = a.user_id\n",
    "    WHERE \n",
    "        lifetime <= 7\n",
    "    GROUP BY \n",
    "        c.cohort\n",
    "        , lifetime\n",
    "    ORDER BY \n",
    "        c.cohort  \n",
    "\"\"\"\n",
    "\n",
    "QUERY_ROLL_RETENTION_7D = \"\"\"\n",
    "    WITH users as (\n",
    "        SELECT \n",
    "            user_id\n",
    "            , max(toDate(time) = yesterday()) as returned_yesterday\n",
    "            , max(toDate(time) != yesterday()) as returned_prev_week\n",
    "        FROM (\n",
    "            SELECT\n",
    "                time\n",
    "                , user_id\n",
    "            FROM \n",
    "                feed_actions\n",
    "            UNION ALL \n",
    "            SELECT\n",
    "                time\n",
    "                , user_id\n",
    "            FROM \n",
    "                message_actions \n",
    "        )\n",
    "        WHERE \n",
    "            toDate(time) BETWEEN yesterday() - 7 AND yesterday()\n",
    "        GROUP BY \n",
    "            user_id\n",
    "    )\n",
    "    SELECT \n",
    "        sum(returned_yesterday) as yesterday_users\n",
    "        , sum(returned_yesterday AND returned_prev_week) as all_week_users\n",
    "        , all_week_users / yesterday_users as retention_7d\n",
    "    FROM \n",
    "        users\n",
    "\"\"\"\n",
    "\n",
    "QUERY_FEED_DETAILED = \"\"\"\n",
    "    WITH users_stats as (\n",
    "        SELECT \n",
    "            toDate(time) as date\n",
    "            , user_id\n",
    "            , uniq(post_id) as posts\n",
    "            , countIf(action = 'view') as views\n",
    "            , countIf(action = 'like') as likes\n",
    "            , ifNull(likes / nullIf(views, 0), 0) as ctr\n",
    "        FROM \n",
    "            feed_actions\n",
    "        WHERE \n",
    "            toDate(time) BETWEEN yesterday() - 13 AND yesterday()\n",
    "        GROUP BY \n",
    "            date\n",
    "            , user_id\n",
    "    )\n",
    "    SELECT \n",
    "        date\n",
    "        , if(date >= yesterday() - 6, 'current', 'previous') as week_status\n",
    "        , AVG(posts) as posts_per_user\n",
    "        , AVG(views) as views_per_user\n",
    "        , AVG(likes) as likes_per_user\n",
    "        , AVG(ctr) as ctr_per_user\n",
    "    FROM \n",
    "        users_stats\n",
    "    GROUP BY \n",
    "        date\n",
    "\"\"\"\n",
    "\n",
    "QUERY_MESSENGER_DETAILED = \"\"\"\n",
    "    SELECT \n",
    "        toDate(time) as date\n",
    "        , if(date >= yesterday() - 6, 'current', 'previous') as week_status\n",
    "        , uniq(user_id) as sender_dau\n",
    "        , uniq(receiver_id) as receiver_dau\n",
    "        , ifNull(sender_dau / nullIf(receiver_dau, 0), 0) as sender_to_receiver_ratio\n",
    "        , ifNull(count() / nullIf(sender_dau, 0), 0) as messages_per_sender\n",
    "    FROM \n",
    "        message_actions\n",
    "    WHERE \n",
    "        toDate(time) BETWEEN yesterday() - 13 AND yesterday()\n",
    "    GROUP BY \n",
    "        date\n",
    "    ORDER BY \n",
    "        date        \n",
    "\"\"\"\n",
    "\n",
    "QUERY_USERS_DAILY_BY_SOURCE = \"\"\"\n",
    "    WITH union_data as (\n",
    "        SELECT \n",
    "            toDate(time) as date\n",
    "            , user_id \n",
    "            , max(service = 'feed') as has_feed\n",
    "            , max(service = 'messenger') as has_messenger\n",
    "            , any(source) as source\n",
    "        FROM (\n",
    "            SELECT\n",
    "                time\n",
    "                , user_id\n",
    "                , 'feed' as service\n",
    "                , source\n",
    "            FROM \n",
    "                feed_actions\n",
    "            UNION ALL\n",
    "            SELECT\n",
    "                time\n",
    "                , user_id\n",
    "                , 'messenger' as service\n",
    "                , source\n",
    "            FROM \n",
    "                message_actions \n",
    "        )\n",
    "        WHERE \n",
    "            toDate(time) BETWEEN yesterday() - 6 AND yesterday()  \n",
    "        GROUP BY \n",
    "            date\n",
    "            , user_id \n",
    "    )\n",
    "    SELECT \n",
    "        date\n",
    "        , source\n",
    "        , uniq(user_id) as total_dau\n",
    "        , uniqIf(user_id, has_feed = 1 and has_messenger = 0) as feed_only_dau\n",
    "        , uniqIf(user_id, has_feed = 0 and has_messenger = 1) as messenger_only_dau\n",
    "        , uniqIf(user_id, has_feed = 1 and has_messenger = 1) as both_services_dau\n",
    "    FROM \n",
    "        union_data\n",
    "    GROUP BY \n",
    "        date\n",
    "        , source\n",
    "    ORDER BY \n",
    "        date   \n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df923d1",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761eda6",
   "metadata": {},
   "source": [
    "Create a function for number formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598804f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_number(value, variable_type=None):\n",
    "    \"\"\"Formats numbers for beautiful display\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "    \n",
    "    if variable_type and 'ctr' in variable_type or variable_type == 'ratio':\n",
    "        return f\"{value:.1%}\"\n",
    "    elif variable_type == 'rate':\n",
    "        return f\"{value:.2f}\"\n",
    "    elif isinstance(value, (int, float)):\n",
    "        if abs(value) >= 1e6:\n",
    "            return f\"{value/1e6:.1f}M\"\n",
    "        elif abs(value) >= 1e3:\n",
    "            return f\"{value/1e3:.0f}K\"\n",
    "        else:\n",
    "            return f\"{value:.0f}\"\n",
    "    else:\n",
    "        return str(value)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c40631",
   "metadata": {},
   "source": [
    "Create a function to fill missing dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b6323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complete_missing_dates(df, date_column='date', days_back=13):\n",
    "    \"\"\"\n",
    "    Complete missing dates in dataframe with zeros and current week status.\n",
    "    \"\"\"\n",
    "    # Create full date range\n",
    "    end_date = datetime.now().date() - pd.Timedelta(days=1)\n",
    "    start_date = end_date - pd.Timedelta(days=days_back)\n",
    "    full_range = pd.date_range(start=start_date, end=end_date, name=date_column)\n",
    "    \n",
    "    # Reindex to complete missing dates\n",
    "    df_complete = (\n",
    "        df\n",
    "        .sort_values(date_column)\n",
    "        .set_index(date_column)\n",
    "        .reindex(full_range)\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Fill missing values\n",
    "    df_complete['week_status'] = df_complete['week_status'].fillna('current')\n",
    "    df_complete = df_complete.fillna(0)\n",
    "    \n",
    "    return df_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d7b12",
   "metadata": {},
   "source": [
    "Create a function to calculate WoW (Week-over-Week) change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087d7267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_wow(df: pd.DataFrame, date_col: str='date') -> pd.DataFrame:\n",
    "    \"\"\"Add wow to DataFrame\"\"\"\n",
    "    df = df.sort_values(date_col)\n",
    "    df_wow = (\n",
    "        df.iloc[[6, 13]]\n",
    "        .drop(date_col, axis=1)\n",
    "        .set_index('week_status')\n",
    "    )\n",
    "    df_wow.loc['wow'] = (df_wow.loc['current'].astype('float') - df_wow.loc['previous'].astype('float')) / df_wow.loc['previous'].astype('float')\n",
    "    return df_wow    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91590062",
   "metadata": {},
   "source": [
    "Create a function to format metrics for the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f86f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_metrics_report_wow(df: pd.DataFrame, metrics: dict, header: str=None):\n",
    "    \"\"\"\n",
    "    Uses symbols for alignment in Telegram\n",
    "    \"\"\"\n",
    "    report_lines = []\n",
    "    if header:\n",
    "        report_lines.append(header + '\\n')\n",
    "    for metric in metrics.keys():\n",
    "        current_value = df.loc['current', metric]\n",
    "        current_value = format_number(value=current_value, variable_type=metric)\n",
    "        wow_change = df.loc['wow', metric]\n",
    "        circle = \"🟢\" if wow_change > 0 else \"🔴\" if wow_change < 0 else \"⚪\"\n",
    "        line = f\"{metrics[metric][1]} {metrics[metric][0]}: {current_value} {circle} {wow_change:+.1%} WoW\"\n",
    "        report_lines.append(line)\n",
    "    \n",
    "    return \"\\n\".join(report_lines)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f92f0f",
   "metadata": {},
   "source": [
    "Create a function to prepare the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_comparison_df(\n",
    "    df: pd.DataFrame\n",
    "    , date_col: str\n",
    "    , id_var: str\n",
    "    , has_previous: bool\n",
    "    , value_in_id_var_for_text: str=None\n",
    "    , text_format: str=None\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"Prepares data for comparing the current and previous week\"\"\"\n",
    "    if id_var not in df.columns:\n",
    "        raise ValueError(f\"DataFrame must contain {id_var} column\")    \n",
    "    if has_previous:\n",
    "        df.loc[df[id_var] == 'previous', date_col] += pd.Timedelta(days=7)\n",
    "    df = (\n",
    "        df.melt(\n",
    "            id_vars=[date_col, id_var]\n",
    "        ) \n",
    "    )\n",
    "    if value_in_id_var_for_text:\n",
    "        mask = df[id_var]==value_in_id_var_for_text\n",
    "        mask &= df.groupby('variable')[date_col].transform(\n",
    "            lambda x: x.isin([x.min(), x.max()])\n",
    "        )\n",
    "        df['text'] = df['value'].where(mask)\n",
    "        if text_format:\n",
    "            df['text'] = df['text'].apply(lambda x: f\"{x:{text_format}}\")\n",
    "        else:\n",
    "            df['text'] = [format_number(v, var) for v, var in zip(df['text'], df['variable'])]\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdc3733",
   "metadata": {},
   "source": [
    "Create a function to render charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418bb6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_comparison_dashboard(\n",
    "    df: pd.DataFrame\n",
    "    , date_col: str\n",
    "    , color: str\n",
    "    , metrics: list\n",
    "    , metric_titles: list\n",
    "    , title: str\n",
    "    , make_gray: bool\n",
    "    , text: str=None\n",
    "    , category_orders: dict=None\n",
    "    , tickformats: list=None\n",
    "    , trace_name_for_text: str=None\n",
    "    , labels: dict=None\n",
    "    , trace_names_map: dict=None\n",
    "    ) -> go.Figure:\n",
    "    \"\"\"Creates a 2x2 dashboard for comparing metrics\"\"\"\n",
    "    fig = px.line(\n",
    "        df\n",
    "        , x=date_col\n",
    "        , y='value'\n",
    "        , color=color\n",
    "        , text=text\n",
    "        , facet_col='variable'\n",
    "        , facet_col_wrap=2\n",
    "        , facet_col_spacing=0.08\n",
    "        , facet_row_spacing=0.15\n",
    "        , category_orders=category_orders\n",
    "        , labels=labels\n",
    "        , line_shape='spline'\n",
    "        , title=title\n",
    "        , width=1000\n",
    "        , height=600\n",
    "    )\n",
    "    # Set up lines\n",
    "    added_legends = []\n",
    "    for trace in fig.data:\n",
    "        # Update trace\n",
    "        trace.showlegend = False\n",
    "        trace.mode = 'lines+markers'\n",
    "        if make_gray:\n",
    "            if trace.name == trace_name_for_text:\n",
    "                trace.update(\n",
    "                    mode='lines+markers+text',\n",
    "                    textposition='top center',\n",
    "                    line=dict(color='#777777'),\n",
    "                    marker=dict(color='#777777'),\n",
    "                )\n",
    "            else:  \n",
    "                trace.update(\n",
    "                    line=dict(color='#C1C1C1', dash='dash'), \n",
    "                    marker=dict(color='#C1C1C1'),       \n",
    "                )\n",
    "        if trace.name not in added_legends:\n",
    "            added_legends.append(trace.name)\n",
    "            legend_name = trace_names_map[trace.name] if trace_names_map else trace.name\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[None], y=[None],\n",
    "                mode=trace.mode.replace('+text', ''),\n",
    "                name=legend_name,  \n",
    "                legendgroup=trace.legendgroup,\n",
    "                showlegend=True,\n",
    "                line=dict(color=trace.line.color)\n",
    "            ))                \n",
    "    fig.update_layout(legend_title=None, legend_itemsizing='constant')\n",
    "    fig.update_xaxes(matches=None, tickformat='%b %d', dtick='1D', showticklabels=True)\n",
    "    fig.update_yaxes(matches=None, showticklabels=True, title=None)\n",
    "    # Use formats of values ​​if indicated\n",
    "    if tickformats:\n",
    "        for tickformat, row, col in tickformats:\n",
    "            fig.update_yaxes(tickformat=tickformat, row=row, col=col)\n",
    "    # Update the headlines of the metrics\n",
    "    # Correct order for 2x2 nets\n",
    "    metric_titles = [metric_titles[2], metric_titles[3], metric_titles[0], metric_titles[1]]\n",
    "    for i, annotation in enumerate(fig.layout.annotations):\n",
    "        annotation.text = metric_titles[i]\n",
    "    # Adjust Y-axis ranges to accommodate text labels\n",
    "    # Add 10% padding based on data range for each subplot\n",
    "    if trace_name_for_text:\n",
    "        yaxis_map = {metrics[0]: 'yaxis3', metrics[1]: 'yaxis4', metrics[2]: 'yaxis', metrics[3]: 'yaxis2'}\n",
    "        for variable in df['variable'].unique():\n",
    "            subset = df[df['variable'] == variable]\n",
    "            min_val = subset['value'].min()\n",
    "            max_val = subset['value'].max()\n",
    "            delta = (max_val - min_val) * 0.1  \n",
    "            yaxis_name = yaxis_map[variable]\n",
    "            \n",
    "            if yaxis_name in fig.layout:\n",
    "                fig.layout[yaxis_name]['range'] = (min_val - delta, max_val + delta)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaeafb4",
   "metadata": {},
   "source": [
    "Create a function to render retention charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e1dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_retention_dashboard(df_retention):\n",
    "    \"\"\"Create Dashboard with Retention Heatmap and Line Chart\"\"\"\n",
    "    \n",
    "    # Data preparation for Line Chart\n",
    "    df_retention_7d = (\n",
    "        df_retention\n",
    "        .reset_index()\n",
    "        .rename_axis(columns=None)    \n",
    "        [['cohort', 7]]\n",
    "        .copy()\n",
    "        .rename(columns={7: 'retention_7_day'})\n",
    "    )\n",
    "    df_retention_7d['text'] = np.nan\n",
    "    df_retention_7d.loc[[0, df_retention_7d.index[-1]], 'text'] = (\n",
    "        df_retention_7d['retention_7_day']\n",
    "        .apply(lambda x: f\"{x:.1%}\")\n",
    "    )\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Retention First Week Performance', '7-Day Retention by Cohort'),\n",
    "        horizontal_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    heatmap_fig = go.Heatmap(\n",
    "        z=df_retention.values,\n",
    "        x=df_retention.columns,\n",
    "        y=df_retention.index.strftime('%b %d'),\n",
    "        colorscale='Greens',\n",
    "        colorbar=dict(\n",
    "            tickformat='.0%',\n",
    "            x=0.43,  \n",
    "            y=0.5,  \n",
    "            xanchor='left',  \n",
    "            yanchor='middle', \n",
    "            thickness=15,  \n",
    "        ),\n",
    "    )\n",
    "    fig.add_trace(heatmap_fig, row=1, col=1)\n",
    "    \n",
    "    # Right figure - Line Chart\n",
    "    line_fig = go.Scatter(\n",
    "        x=df_retention_7d['cohort'],\n",
    "        y=df_retention_7d['retention_7_day'],\n",
    "        mode='lines+markers+text',\n",
    "        text=df_retention_7d['text'],\n",
    "        textposition='top center',\n",
    "        line=dict(color='#777777', shape='spline'),\n",
    "        marker=dict(color='#777777')\n",
    "    )\n",
    "    fig.add_trace(line_fig, row=1, col=2)\n",
    "    \n",
    "    # Update Layout\n",
    "    fig.update_layout(\n",
    "        height=400,\n",
    "        width=1100,\n",
    "        showlegend=False,\n",
    "        title_text=\"Retention Analysis Dashboard\",\n",
    "        margin=dict(l=90, r=20)\n",
    "    )\n",
    "    \n",
    "    # Setting axes for Heatmap (left figure)\n",
    "    fig.update_xaxes(\n",
    "        title_text='Lifetime',\n",
    "        title_standoff=7,\n",
    "        type='category', \n",
    "        showgrid=False,\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text='Cohort',\n",
    "        title_standoff=10,\n",
    "        type='category',  \n",
    "        showgrid=False,\n",
    "        autorange='reversed',\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Setting axes for Line Chart (right figure)\n",
    "    fig.update_xaxes(\n",
    "        title_text='Cohort',\n",
    "        tickformat='%b %d',\n",
    "        title_standoff=7,\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text='7-Day Retention',\n",
    "        title_standoff=10,\n",
    "        tickformat='.0%',\n",
    "        row=1, col=2\n",
    "    )\n",
    "    vmax = df_retention.max().max()\n",
    "    vmin = df_retention.min().min()\n",
    "    center_color_bar = vmin + (vmax - vmin) * 0.7 if (vmax - vmin) > 0 else vmin\n",
    "    \n",
    "    for row in range(len(df_retention)):\n",
    "        for col in range(len(df_retention.columns)):\n",
    "            fig.add_annotation(\n",
    "                text=f\"{df_retention.values[row, col]:.0%}\",\n",
    "                x=col,\n",
    "                y=row,\n",
    "                xref=\"x\",\n",
    "                yref=\"y\",\n",
    "                showarrow=False,\n",
    "                font=dict(\n",
    "                    color=\"white\" if df_retention.values[row, col] >= center_color_bar else \"rgba(0, 0, 0, 0.7)\",\n",
    "                    size=10\n",
    "                ),\n",
    "                xanchor='center',\n",
    "                yanchor='middle',\n",
    "                row=1,  \n",
    "                col=1  \n",
    "            )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fbed68",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Airflow DAG Implementation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a17cd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Complete DAG code for automated daily report generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad1b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dag_app_daily_report.py\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from telegram import InputFile\n",
    "from airflow.decorators import dag, task\n",
    "from airflow.operators.python import get_current_context\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "sys.path.insert(0, current_dir)\n",
    "from utils_for_dags import (\n",
    "    ChConnector\n",
    "    , TelegramBot\n",
    "    , calc_wow\n",
    "    , format_number\n",
    "    , format_metrics_report_wow\n",
    "    , prepare_comparison_df\n",
    "    , create_comparison_dashboard\n",
    "    , create_retention_dashboard\n",
    "    , complete_missing_dates    \n",
    ")\n",
    "from app_daily_report_queries import (\n",
    "    QUERY_DAU\n",
    "    , QUERY_NEW_USERS\n",
    "    , QUERY_ACTIVITY\n",
    "    , QUERY_RETENTION\n",
    "    , QUERY_ROLL_RETENTION_7D\n",
    "    , QUERY_FEED_DETAILED\n",
    "    , QUERY_MESSENGER_DETAILED\n",
    "    , QUERY_USERS_DAILY_BY_SOURCE\n",
    ")\n",
    "\n",
    "db = ChConnector()\n",
    "bot = TelegramBot()\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'Pavel Grigoryev',\n",
    "    'depends_on_past': False,\n",
    "    'retries': 2,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    'start_date': datetime(2025, 9, 25),\n",
    "}\n",
    "\n",
    "dag_config = {\n",
    "    'default_args': default_args,\n",
    "    'description': 'DAG for sending a daily report in Telegram',\n",
    "    'schedule_interval': '0 11 * * *',\n",
    "    'catchup': False,\n",
    "    'tags': ['daily_report'],\n",
    "    'max_active_runs': 1,\n",
    "}\n",
    "\n",
    "def handle_failure(context):\n",
    "    \"\"\"\n",
    "    Callback function for processing unsuccessful tasks\n",
    "    \"\"\"\n",
    "    exception = context.get('exception')\n",
    "    task_instance = context['task_instance']\n",
    "\n",
    "    print(f\"Task {task_instance.task_id} It ended with an error:\")\n",
    "    print(f\"Error: {exception}\")\n",
    "    print(f\"Date of execution: {context['ds']}\")\n",
    "    print(f\"Attempt №: {context['ti'].try_number}\")\n",
    "\n",
    "@dag(**dag_config)\n",
    "def app_report():\n",
    "    \"\"\"\n",
    "    DAG every day extracts data from the database, calculates metric, builds graphs, creates report and sends it to Telegram\n",
    "    \"\"\"\n",
    "    # ==========================================================================\n",
    "    # Extract\n",
    "    # ==========================================================================\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def extract_dau() -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extracts data from the database\n",
    "        \"\"\"\n",
    "        df = db.get_df(query=QUERY_DAU)\n",
    "        return complete_missing_dates(df)\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def extract_new_users() -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extracts data from the database\n",
    "        \"\"\"\n",
    "        df = db.get_df(query=QUERY_NEW_USERS)\n",
    "        return complete_missing_dates(df)\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def extract_activity() -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extracts data from the database\n",
    "        \"\"\"\n",
    "        df = db.get_df(query=QUERY_ACTIVITY)\n",
    "        return complete_missing_dates(df)\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def extract_retention() -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extracts data from the database\n",
    "        \"\"\"\n",
    "        return db.get_df(query=QUERY_RETENTION)\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def extract_roll_retention_7d() -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extracts data from the database\n",
    "        \"\"\"\n",
    "        return db.get_df(query=QUERY_ROLL_RETENTION_7D)\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def extract_feed_detailed() -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extracts data from the database\n",
    "        \"\"\"\n",
    "        df = db.get_df(query=QUERY_FEED_DETAILED)\n",
    "        return complete_missing_dates(df)\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def extract_messenger_detailed() -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extracts data from the database\n",
    "        \"\"\"\n",
    "        df = db.get_df(query=QUERY_MESSENGER_DETAILED)\n",
    "        return complete_missing_dates(df)\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def extract_users_daily_by_source() -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extracts data from the database\n",
    "        \"\"\"\n",
    "        return db.get_df(query=QUERY_USERS_DAILY_BY_SOURCE)\n",
    "\n",
    "    # ==========================================================================\n",
    "    # Transform\n",
    "    # ==========================================================================\n",
    "\n",
    "    # DAU\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure,\n",
    "        multiple_outputs=True\n",
    "    )\n",
    "    def transform_dau(df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Calculates the growth of WOW\n",
    "        \"\"\"\n",
    "        context = get_current_context()\n",
    "        yesterday = context['execution_date']  # execution_date is period start for schedule_interval = '0 8 * * *'\n",
    "        date_str = yesterday.strftime('%d %b %Y')          \n",
    "        df_wow = calc_wow(df)\n",
    "        df_comparison = prepare_comparison_df(\n",
    "            df=df\n",
    "            , date_col='date'\n",
    "            , id_var='week_status'\n",
    "            , value_in_id_var_for_text='current'\n",
    "            , has_previous=True\n",
    "        )\n",
    "        metrics = {\n",
    "            'total_dau': ['Total', '• 👥'],\n",
    "            'feed_only_dau': ['Feed Only', '• 📰'],\n",
    "            'messenger_only_dau': ['Messenger Only', '• 💬'],\n",
    "            'both_services_dau': ['Both Services', '• 🔄']\n",
    "        }\n",
    "        msg = format_metrics_report_wow(df_wow, metrics, f'📊 App Report 📅 {date_str}\\n\\n👤 Daily Active Users')\n",
    "\n",
    "        metrics = ['total_dau', 'feed_only_dau', 'messenger_only_dau', 'both_services_dau']\n",
    "        metric_titles = ['Total DAU', 'Feed Only DAU', 'Messenger Only DAU', 'Both Services DAU']\n",
    "        category_orders={'variable': metrics, 'week_status': ['current', 'previous']}\n",
    "\n",
    "        fig = create_comparison_dashboard(\n",
    "            df=df_comparison\n",
    "            , date_col='date'\n",
    "            , color='week_status'\n",
    "            , text='text'\n",
    "            , metrics=metrics\n",
    "            , metric_titles=metric_titles\n",
    "            , trace_name_for_text='current'\n",
    "            , title='Daily Active Users'\n",
    "            , labels={'date': 'Date'}\n",
    "            , category_orders=category_orders\n",
    "            , trace_names_map={'current': 'Current Week', 'previous': 'Previous Week'}\n",
    "            , make_gray=True\n",
    "        )\n",
    "        return {\"msg\": msg, \"fig\": fig}\n",
    "\n",
    "    # New Users\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure,\n",
    "        multiple_outputs=True\n",
    "    )\n",
    "    def transform_new_users(df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Calculates the growth of WOW\n",
    "        \"\"\"       \n",
    "        df_wow = calc_wow(df)\n",
    "        df_comparison = prepare_comparison_df(\n",
    "            df=df\n",
    "            , date_col='date'\n",
    "            , id_var='week_status'\n",
    "            , value_in_id_var_for_text='current'\n",
    "            , has_previous=True\n",
    "        )\n",
    "        metrics = {\n",
    "            'all_new_users': ['All New Users', '• 👥'],\n",
    "            'feed_new_users': ['Feed New Users', '• 📰'],\n",
    "            'messenger_new_users': ['Msg New Users', '• 💬'],\n",
    "            'both_first_users': ['Used Both First Time', '• 🔄']\n",
    "        }\n",
    "        msg = format_metrics_report_wow(df_wow, metrics, '🆕 New Users & First Usage')\n",
    "\n",
    "        metrics = ['all_new_users', 'feed_new_users', 'messenger_new_users', 'both_first_users']\n",
    "        metric_titles = ['All New Users', 'Feed New Users', 'Msg New Users', 'Used Both First Time']\n",
    "        category_orders={'variable': metrics, 'week_status': ['current', 'previous']}\n",
    "\n",
    "        fig = create_comparison_dashboard(\n",
    "            df=df_comparison\n",
    "            , date_col='date'\n",
    "            , color='week_status'\n",
    "            , text='text'\n",
    "            , metrics=metrics\n",
    "            , metric_titles=metric_titles\n",
    "            , trace_name_for_text='current'\n",
    "            , title='New Users Activity'\n",
    "            , labels={'date': 'Date'}\n",
    "            , category_orders=category_orders\n",
    "            , trace_names_map={'current': 'Current Week', 'previous': 'Previous Week'}\n",
    "            , make_gray=True\n",
    "        )\n",
    "        return {\"msg\": msg, \"fig\": fig}\n",
    "\n",
    "    # Activity\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure,\n",
    "        multiple_outputs=True\n",
    "    )\n",
    "    def transform_activity(df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Calculates the growth of WOW\n",
    "        \"\"\"\n",
    "        df_wow = calc_wow(df)\n",
    "        df_comparison = prepare_comparison_df(\n",
    "            df=df\n",
    "            , date_col='date'\n",
    "            , id_var='week_status'\n",
    "            , value_in_id_var_for_text='current'\n",
    "            , has_previous=True\n",
    "        )\n",
    "\n",
    "        metrics = {\n",
    "            'views': ['Views', '• 👀'],\n",
    "            'likes': ['Likes', '• ❤️'],\n",
    "            'ctr': ['CTR', '• 🎯'],\n",
    "            'messages': ['Messages', '• ✉️']\n",
    "        }\n",
    "        msg = format_metrics_report_wow(df_wow, metrics, '🔥 Activity Metrics')\n",
    "\n",
    "        metrics = ['views', 'likes', 'ctr', 'messages']\n",
    "        metric_titles = ['Views', 'Likes', 'CTR', 'Messages']\n",
    "        category_orders={'variable': metrics, 'week_status': ['current', 'previous']}\n",
    "\n",
    "        fig = create_comparison_dashboard(\n",
    "            df=df_comparison\n",
    "            , date_col='date'\n",
    "            , color='week_status'\n",
    "            , text='text'\n",
    "            , metrics=metrics\n",
    "            , metric_titles=metric_titles\n",
    "            , trace_name_for_text='current'\n",
    "            , title='Activity Metrics'\n",
    "            , labels={'date': 'Date'}\n",
    "            , category_orders=category_orders\n",
    "            , trace_names_map={'current': 'Current Week', 'previous': 'Previous Week'}\n",
    "            , make_gray=True\n",
    "        )\n",
    "        return {\"msg\": msg, \"fig\": fig}\n",
    "\n",
    "    # Retention\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure,\n",
    "        multiple_outputs=True\n",
    "    )\n",
    "    def transform_retention(df: pd.DataFrame, df_roll: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Creates a DataFrame for comparison\n",
    "        \"\"\"\n",
    "        df_cohort = df.pivot_table(index='cohort', columns='lifetime', values='users', fill_value=0)\n",
    "        df_retention = (\n",
    "            df_cohort.div(df_cohort[0], axis=0)\n",
    "            .drop(0, axis=1)\n",
    "        )\n",
    "\n",
    "        df_retention_7d = df_retention[7]\n",
    "        df_retention_7d.index = df_retention_7d.index.strftime('%b %d')\n",
    "        mean_retention = df_retention_7d.mean()\n",
    "        best_cohort = df_retention_7d.agg(['idxmax', 'max'])\n",
    "        worst_cohort = df_retention_7d.agg(['idxmin', 'min'])\n",
    "        spread = abs(best_cohort['max'] - worst_cohort['min']) * 100\n",
    "        yesterday_dau = format_number(int(df_roll['yesterday_users'].iloc[0]))\n",
    "        all_week_users = format_number(int(df_roll['all_week_users'].iloc[0]))\n",
    "        msg = dedent(f\"\"\"\n",
    "        🎯 Retention Analysis\n",
    "\n",
    "        7-Day Cohort Retention\n",
    "        (Last 7 completed cohorts)\n",
    "        • ⚖️ Mean: {mean_retention:.1%}\n",
    "        • 🏆 Best Cohort: {best_cohort['max']:.1%} ({best_cohort['idxmax']})\n",
    "        • ⚠️ Worst Cohort: {worst_cohort['min']:.1%} ({worst_cohort['idxmin']})\n",
    "        • ↔️ Spread: {spread:.1f} pp\n",
    "\n",
    "        Rolling Retention 7D (Current Audience)\n",
    "        • 👥 Yesterday's DAU: {yesterday_dau}\n",
    "        • 📅 Active in last 7 days: {all_week_users}\n",
    "        • 🎯 Rolling Retention: {df_roll['retention_7d'].iloc[0]:.1%}\n",
    "        \"\"\")\n",
    "\n",
    "        fig = create_retention_dashboard(df_retention=df_retention)\n",
    "        return {\"msg\": msg, \"fig\": fig}\n",
    "\n",
    "    # Feed Detailed\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure,\n",
    "        multiple_outputs=True\n",
    "    )\n",
    "    def transform_feed(df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Calculates the growth of WOW\n",
    "        \"\"\"\n",
    "        df_wow = calc_wow(df)\n",
    "        df_comparison = prepare_comparison_df(\n",
    "            df=df\n",
    "            , date_col='date'\n",
    "            , id_var='week_status'\n",
    "            , value_in_id_var_for_text='current'\n",
    "            , has_previous=True\n",
    "        )\n",
    "\n",
    "        metrics = {\n",
    "            'posts_per_user': ['Posts per User', '• 📝'],\n",
    "            'views_per_user': ['Views per User', '• 👀'],\n",
    "            'likes_per_user': ['Likes per User', '• ❤️'],\n",
    "            'ctr_per_user': ['CTR per User', '• 🎯']\n",
    "        }\n",
    "        msg = format_metrics_report_wow(df_wow, metrics, '📰 Feed Detailed')\n",
    "\n",
    "        metrics = ['posts_per_user', 'views_per_user', 'likes_per_user', 'ctr_per_user']\n",
    "        metric_titles = ['Posts per User', 'Views per User', 'Likes per User', 'CTR per User']\n",
    "        category_orders={'variable': metrics, 'week_status': ['current', 'previous']}\n",
    "\n",
    "        fig = create_comparison_dashboard(\n",
    "            df=df_comparison\n",
    "            , date_col='date'\n",
    "            , color='week_status'\n",
    "            , text='text'\n",
    "            , metrics=metrics\n",
    "            , metric_titles=metric_titles\n",
    "            , trace_name_for_text='current'\n",
    "            , title = 'Feed Detailed Metrics'\n",
    "            , labels={'date': 'Date'}\n",
    "            , category_orders=category_orders\n",
    "            , trace_names_map={'current': 'Current Week', 'previous': 'Previous Week'}\n",
    "            , tickformats=[['.1%', 1, 2]]\n",
    "            , make_gray=True\n",
    "        )\n",
    "        return {\"msg\": msg, \"fig\": fig}\n",
    "\n",
    "    # Messenger Detailed\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure,\n",
    "        multiple_outputs=True\n",
    "    )\n",
    "    def transform_messenger(df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Calculates the growth of WOW\n",
    "        \"\"\"\n",
    "        df_wow = calc_wow(df)\n",
    "        df_comparison = prepare_comparison_df(\n",
    "            df=df\n",
    "            , date_col='date'\n",
    "            , id_var='week_status'\n",
    "            , value_in_id_var_for_text='current'\n",
    "            , has_previous=True\n",
    "        )\n",
    "\n",
    "        metrics = {\n",
    "            'sender_dau': ['Sender DAU', '• 📢'],\n",
    "            'receiver_dau': ['Receiver DAU', '• 📭'],\n",
    "            'sender_to_receiver_ratio': ['Sender DAU / Receiver DAU', '• ⚖️'],\n",
    "            'messages_per_sender': ['Messages per Sender', '• ✉️']\n",
    "        }\n",
    "        msg = format_metrics_report_wow(df_wow, metrics, '💬 Messenger Detailed')\n",
    "\n",
    "        metrics = ['sender_dau', 'receiver_dau', 'sender_to_receiver_ratio', 'messages_per_sender']\n",
    "        metric_titles = ['Sender DAU', 'Receiver DAU', 'Sender DAU / Receiver DAU', 'Messages per Sender']\n",
    "        category_orders={'variable': metrics, 'week_status': ['current', 'previous']}\n",
    "\n",
    "        fig = create_comparison_dashboard(\n",
    "            df=df_comparison\n",
    "            , date_col='date'\n",
    "            , color='week_status'\n",
    "            , text='text'\n",
    "            , metrics=metrics\n",
    "            , metric_titles=metric_titles\n",
    "            , trace_name_for_text='current'\n",
    "            , title = 'Messenger Detailed Metrics'\n",
    "            , labels={'date': 'Date'}\n",
    "            , category_orders=category_orders\n",
    "            , trace_names_map={'current': 'Current Week', 'previous': 'Previous Week'}\n",
    "            , make_gray=True\n",
    "        )\n",
    "        return {\"msg\": msg, \"fig\": fig}\n",
    "\n",
    "    # DAU by Source\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure,\n",
    "        multiple_outputs=True\n",
    "    )\n",
    "    def transform_by_source(df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Creates a DataFrame for comparison\n",
    "        \"\"\"\n",
    "        df_comparison = prepare_comparison_df(\n",
    "            df=df\n",
    "            , date_col='date'\n",
    "            , id_var='source'\n",
    "            , has_previous=False\n",
    "        )\n",
    "\n",
    "        mask = df['date'] == df['date'].max()\n",
    "        latest_data = df[mask]\n",
    "\n",
    "        total_dau = latest_data['total_dau'].sum()\n",
    "        ads_dau = latest_data[latest_data['source'] == 'ads']['total_dau'].iloc[0]\n",
    "        organic_dau = latest_data[latest_data['source'] == 'organic']['total_dau'].iloc[0]\n",
    "\n",
    "        ads_share = ads_dau / total_dau\n",
    "        organic_share = organic_dau / total_dau\n",
    "\n",
    "        ads_feed_share = latest_data[latest_data['source'] == 'ads']['feed_only_dau'].iloc[0] / ads_dau\n",
    "        ads_messenger_share = latest_data[latest_data['source'] == 'ads']['messenger_only_dau'].iloc[0] / ads_dau\n",
    "        ads_both_share = latest_data[latest_data['source'] == 'ads']['both_services_dau'].iloc[0] / ads_dau\n",
    "\n",
    "        organic_feed_share = latest_data[latest_data['source'] == 'organic']['feed_only_dau'].iloc[0] / organic_dau\n",
    "        organic_messenger_share = latest_data[latest_data['source'] == 'organic']['messenger_only_dau'].iloc[0] / organic_dau\n",
    "        organic_both_share = latest_data[latest_data['source'] == 'organic']['both_services_dau'].iloc[0] / organic_dau\n",
    "\n",
    "        msg =  dedent(f\"\"\"\n",
    "            🌐 Active Users by Source \n",
    "\n",
    "            👥 Total DAU: {total_dau:,.0f}\n",
    "            • Ads: {ads_share:.1%} ({ads_dau:,.0f})\n",
    "            • Organic: {organic_share:.1%} ({organic_dau:,.0f})\n",
    "            📰 Feed Only:\n",
    "            • Ads: {ads_feed_share:.1%} • Organic: {organic_feed_share:.1%}\n",
    "            💬 Messenger Only:\n",
    "            • Ads: {ads_messenger_share:.1%} • Organic: {organic_messenger_share:.1%}\n",
    "            🔄 Both Services:\n",
    "            • Ads: {ads_both_share:.1%} • Organic: {organic_both_share:.1%}\n",
    "        \"\"\")\n",
    "\n",
    "        metrics = ['total_dau', 'feed_only_dau', 'messenger_only_dau', 'both_services_dau']\n",
    "        metric_titles = ['Total DAU', 'Feed Only DAU', 'Messenger Only DAU', 'Both Services DAU']\n",
    "        category_orders={'variable': metrics}\n",
    "        trace_names_map={'ads': 'Ads', 'organic': 'Organic'} \n",
    "\n",
    "        fig = create_comparison_dashboard(\n",
    "            df=df_comparison\n",
    "            , date_col='date'\n",
    "            , color='source'\n",
    "            , metrics=metrics\n",
    "            , metric_titles=metric_titles\n",
    "            , title = 'Daily Active Users by Source'\n",
    "            , labels={'date': 'Date'}\n",
    "            , category_orders=category_orders\n",
    "            , make_gray=False\n",
    "            , trace_names_map=trace_names_map\n",
    "        )\n",
    "        return {\"msg\": msg, \"fig\": fig}\n",
    "\n",
    "    # ==========================================================================\n",
    "    # Load\n",
    "    # ==========================================================================\n",
    "    # DAU\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_dau_message(message: str) -> None:\n",
    "        \"\"\"Task for sending DAU message\"\"\"\n",
    "        print(\"📨 Sending DAU message...\")\n",
    "        if not bot.send_message(message=message):\n",
    "            raise Exception(\"Failed to send DAU message\")\n",
    "        print(\"✅ DAU message sent successfully\")\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_dau_chart(figure: go.Figure) -> None:\n",
    "        \"\"\"Task for sending DAU chart\"\"\"\n",
    "        print(\"📊 Sending DAU chart...\")\n",
    "        if not bot.send_chart(figure=figure):\n",
    "            raise Exception(\"Failed to send DAU chart\")\n",
    "        print(\"✅ DAU chart sent successfully\")\n",
    "\n",
    "    # New users\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_new_users_message(message: str) -> None:\n",
    "        \"\"\"Task for sending new users message\"\"\"\n",
    "        print(\"📨 Sending new users message...\")\n",
    "        if not bot.send_message(message=message):\n",
    "            raise Exception(\"Failed to send new users message\")\n",
    "        print(\"✅ new users message sent successfully\")\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_new_users_chart(figure: go.Figure) -> None:\n",
    "        \"\"\"Task for sending new users chart\"\"\"\n",
    "        print(\"📊 Sending new users chart...\")\n",
    "        if not bot.send_chart(figure=figure):\n",
    "            raise Exception(\"Failed to send new users chart\")\n",
    "        print(\"✅ new users chart sent successfully\")\n",
    "\n",
    "    # Activity\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_activity_message(message: str) -> None:\n",
    "        \"\"\"Task for sending Activity message\"\"\"\n",
    "        print(\"📨 Sending Activity message...\")\n",
    "        if not bot.send_message(message=message):\n",
    "            raise Exception(\"Failed to send Activity message\")\n",
    "        print(\"✅ Activity message sent successfully\")\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_activity_chart(figure: go.Figure) -> None:\n",
    "        \"\"\"Task for sending Activity chart\"\"\"\n",
    "        print(\"📊 Sending Activity chart...\")\n",
    "        if not bot.send_chart(figure=figure):\n",
    "            raise Exception(\"Failed to send Activity chart\")\n",
    "        print(\"✅ Activity chart sent successfully\")\n",
    "\n",
    "    # Retention\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_retention_message(message: str) -> None:\n",
    "        \"\"\"Task for sending Retention message\"\"\"\n",
    "        print(\"📨 Sending Retention message...\")\n",
    "        if not bot.send_message(message=message):\n",
    "            raise Exception(\"Failed to send Retention message\")\n",
    "        print(\"✅ Retention message sent successfully\")\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_retention_chart(figure: go.Figure) -> None:\n",
    "        \"\"\"Task for sending Retention chart\"\"\"\n",
    "        print(\"📊 Sending Retention chart...\")\n",
    "        if not bot.send_chart(figure=figure):\n",
    "            raise Exception(\"Failed to send Retention chart\")\n",
    "        print(\"✅ Retention chart sent successfully\")\n",
    "\n",
    "    # Feed Detailed\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_feed_detailed_message(message: str) -> None:\n",
    "        \"\"\"Task for sending Feed Detailed message\"\"\"\n",
    "        print(\"📨 Sending Feed Detailed message...\")\n",
    "        if not bot.send_message(message=message):\n",
    "            raise Exception(\"Failed to send Feed Detailed message\")\n",
    "        print(\"✅ Feed Detailed message sent successfully\")\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_feed_detailed_chart(figure: go.Figure) -> None:\n",
    "        \"\"\"Task for sending Feed Detailed chart\"\"\"\n",
    "        print(\"📊 Sending Feed Detailed chart...\")\n",
    "        if not bot.send_chart(figure=figure):\n",
    "            raise Exception(\"Failed to send Feed Detailed chart\")\n",
    "        print(\"✅ Feed Detailed chart sent successfully\")\n",
    "\n",
    "    # Messenger Detailed\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_messenger_detailed_message(message: str) -> None:\n",
    "        \"\"\"Task for sending Messenger Detailed message\"\"\"\n",
    "        print(\"📨 Sending Messenger Detailed message...\")\n",
    "        if not bot.send_message(message=message):\n",
    "            raise Exception(\"Failed to send Messenger Detailed message\")\n",
    "        print(\"✅ Messenger Detailed message sent successfully\")\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_messenger_detailed_chart(figure: go.Figure) -> None:\n",
    "        \"\"\"Task for sending Messenger Detailed chart\"\"\"\n",
    "        print(\"📊 Sending Messenger Detailed chart...\")\n",
    "        if not bot.send_chart(figure=figure):\n",
    "            raise Exception(\"Failed to send Messenger Detailed chart\")\n",
    "        print(\"✅ Messenger Detailed chart sent successfully\")\n",
    "\n",
    "    # Users by Source\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_by_source_message(message: str) -> None:\n",
    "        \"\"\"Task for sending Users by Source message\"\"\"\n",
    "        print(\"📨 Sending Users by Source message...\")\n",
    "        if not bot.send_message(message=message):\n",
    "            raise Exception(\"Failed to send Users by Source message\")\n",
    "        print(\"✅ Users by Source message sent successfully\")\n",
    "\n",
    "    @task(\n",
    "        retries=3,\n",
    "        retry_delay=timedelta(minutes=5),\n",
    "        on_failure_callback=handle_failure\n",
    "    )\n",
    "    def load_by_source_chart(figure: go.Figure) -> None:\n",
    "        \"\"\"Task for sending Users by Source chart\"\"\"\n",
    "        print(\"📊 Sending Users by Source chart...\")\n",
    "        if not bot.send_chart(figure=figure):\n",
    "            raise Exception(\"Failed to send Users by Source chart\")\n",
    "        print(\"✅ Users by Source chart sent successfully\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # WORKFLOW\n",
    "    # ==========================================================================\n",
    "\n",
    "    # extract\n",
    "    df_dau = extract_dau()\n",
    "    df_new_users = extract_new_users()\n",
    "    df_activity = extract_activity()\n",
    "    df_retention = extract_retention()\n",
    "    df_roll_retention_7d = extract_roll_retention_7d()\n",
    "    df_feed_detailed = extract_feed_detailed()\n",
    "    df_messenger_detailed = extract_messenger_detailed()\n",
    "    df_users_daily_by_source = extract_users_daily_by_source()\n",
    "\n",
    "    # transform\n",
    "    transform_dau_result = transform_dau(df_dau)\n",
    "    msg_dau = transform_dau_result[\"msg\"]\n",
    "    fig_dau = transform_dau_result[\"fig\"]\n",
    "\n",
    "    transform_new_users_result = transform_new_users(df_new_users)\n",
    "    msg_new_users = transform_new_users_result[\"msg\"]\n",
    "    fig_new_users = transform_new_users_result[\"fig\"]    \n",
    "    \n",
    "    transform_activity_result = transform_activity(df_activity)\n",
    "    msg_activity = transform_activity_result[\"msg\"]\n",
    "    fig_activity = transform_activity_result[\"fig\"]   \n",
    "     \n",
    "    transform_retention_result = transform_retention(df_retention, df_roll_retention_7d)\n",
    "    msg_retention = transform_retention_result[\"msg\"]\n",
    "    fig_retention = transform_retention_result[\"fig\"]    \n",
    "        \n",
    "    transform_feed_detailed_result = transform_feed(df_feed_detailed)\n",
    "    msg_feed_detailed = transform_feed_detailed_result[\"msg\"]\n",
    "    fig_feed_detailed = transform_feed_detailed_result[\"fig\"]      \n",
    "    \n",
    "    transform_messenger_detailed_result = transform_messenger(df_messenger_detailed)\n",
    "    msg_messenger_detailed = transform_messenger_detailed_result[\"msg\"]\n",
    "    fig_messenger_detailed = transform_messenger_detailed_result[\"fig\"]       \n",
    "    \n",
    "    transform_by_source_result = transform_by_source(df_users_daily_by_source)\n",
    "    msg_by_source = transform_by_source_result[\"msg\"]\n",
    "    fig_by_source = transform_by_source_result[\"fig\"]      \n",
    "\n",
    "\n",
    "    # load\n",
    "    dau_msg_task = load_dau_message(msg_dau)\n",
    "    dau_chart_task = load_dau_chart(fig_dau)\n",
    "\n",
    "    new_users_msg_task = load_new_users_message(msg_new_users)  \n",
    "    new_users_chart_task = load_new_users_chart(fig_new_users)\n",
    "    \n",
    "    activity_msg_task = load_activity_message(msg_activity)  \n",
    "    activity_chart_task = load_activity_chart(fig_activity)    \n",
    "\n",
    "    retention_msg_task = load_retention_message(msg_retention)\n",
    "    retention_chart_task = load_retention_chart(fig_retention)\n",
    "\n",
    "    feed_detailed_msg_task = load_feed_detailed_message(msg_feed_detailed)\n",
    "    feed_detailed_chart_task = load_feed_detailed_chart(fig_feed_detailed)   \n",
    "    \n",
    "    messenger_detailed_msg_task = load_messenger_detailed_message(msg_messenger_detailed)\n",
    "    messenger_detailed_chart_task = load_messenger_detailed_chart(fig_messenger_detailed)    \n",
    "            \n",
    "    by_source_msg_task = load_by_source_message(msg_by_source)\n",
    "    by_source_chart_task = load_by_source_chart(fig_by_source)\n",
    "    \n",
    "    # task dependencies\n",
    "    (\n",
    "        dau_msg_task >> dau_chart_task >>\n",
    "        new_users_msg_task >> new_users_chart_task >>\n",
    "        activity_msg_task >> activity_chart_task >>\n",
    "        retention_msg_task >> retention_chart_task >>\n",
    "        feed_detailed_msg_task >> feed_detailed_chart_task >>\n",
    "        messenger_detailed_msg_task >> messenger_detailed_chart_task >>\n",
    "        by_source_msg_task >> by_source_chart_task\n",
    "    )\n",
    "      \n",
    "# ==========================================================================\n",
    "# DAG execution\n",
    "# ==========================================================================\n",
    "\n",
    "app_report = app_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4882a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Report Screenshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb1776",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Below are screenshots of a sample report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2df5d",
   "metadata": {},
   "source": [
    "<img src=\"app_report_telegram_part_1.png\" alt=\"\">\n",
    "<img src=\"app_report_telegram_part_2.png\" alt=\"\">\n",
    "<img src=\"app_report_telegram_part_3.png\" alt=\"\">\n",
    "<img src=\"app_report_telegram_part_4.png\" alt=\"\">\n",
    "<img src=\"app_report_telegram_part_5.png\" alt=\"\">\n",
    "<img src=\"app_report_telegram_part_6.png\" alt=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed60cfc8",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "- **Data Pipeline Development:** \n",
    "  - Built SQL queries to extract and calculate key product metrics from ClickHouse database\n",
    "- **Automation Framework:** \n",
    "  - Created Airflow DAG for scheduled daily execution with comprehensive error handling\n",
    "- **Chat Delivery System:** \n",
    "  - Integrated Telegram API for automated report distribution directly to team chat\n",
    "- **Business Reporting:** \n",
    "  - Designed comprehensive visualizations covering both application-wide and feature-specific metrics\n",
    "- **Stakeholder Focus:** \n",
    "  - Developed business-ready reports that answer key product performance questions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
